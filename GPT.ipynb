{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y9oeNZYDIqAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1NzyJC_Pena",
        "outputId": "a9ef149d-9cab-4be4-d97b-214ff4c03ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0, Loss: {'train': tensor(4.7305), 'val': tensor(4.7241)}\n",
            "Step: 300, Loss: {'train': tensor(2.8110), 'val': tensor(2.8249)}\n",
            "Step: 600, Loss: {'train': tensor(2.5434), 'val': tensor(2.5682)}\n",
            "Step: 900, Loss: {'train': tensor(2.4932), 'val': tensor(2.5088)}\n",
            "Step: 1200, Loss: {'train': tensor(2.4863), 'val': tensor(2.5035)}\n",
            "Step: 1500, Loss: {'train': tensor(2.4665), 'val': tensor(2.4921)}\n",
            "Step: 1800, Loss: {'train': tensor(2.4683), 'val': tensor(2.4936)}\n",
            "Step: 2100, Loss: {'train': tensor(2.4696), 'val': tensor(2.4846)}\n",
            "Step: 2400, Loss: {'train': tensor(2.4638), 'val': tensor(2.4879)}\n",
            "Step: 2700, Loss: {'train': tensor(2.4738), 'val': tensor(2.4911)}\n",
            "\n",
            "\n",
            "\n",
            "CEThik brid owindakis b, bth\n",
            "\n",
            "HAPet bobe d e.\n",
            "S:\n",
            "O:3 my d?\n",
            "LUCous:\n",
            "Wanthar u qur, t.\n",
            "War dXENDoate awice my.\n",
            "\n",
            "Hastarom oroup\n",
            "Yowhthetof isth ble mil ndill, ath iree sengmin lat Heriliovets, and Win nghir.\n",
            "Swanousel lind me l.\n",
            "HAshe ce hiry:\n",
            "Supr aisspllw y.\n",
            "Hentofu n Boopetelaves\n",
            "MPOLI s, d mothakleo Windo whth eisbyo the m dourive we higend t so mower; te\n",
            "\n",
            "AN ad nterupt f s ar igr t m:\n",
            "\n",
            "Thin maleronth,\n",
            "Mad\n",
            "RD:\n",
            "\n",
            "WISo myrangoube!\n",
            "KENob&y, wardsal thes ghesthinin couk ay aney IOUSts I&fr y ce.\n",
            "J\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "max_iters = 3000\n",
        "eval_interval = 300\n",
        "learning_rate = 1e-2\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iters = 200\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [stoi[i] for i in s]\n",
        "decode = lambda l: \"\".join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    X = torch.stack([data[i:i + block_size] for i in ix])\n",
        "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    return X, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, y = get_batch(split)\n",
        "            logits, loss = model(X, y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "    \n",
        "    def forward(self, idx, targets=None):\n",
        "        logits = self.token_embedding_table(idx)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self(idx)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    model = BigramLanguageModel()\n",
        "    m = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    for iter in range(max_iters):\n",
        "        if iter % eval_interval == 0:\n",
        "            losses = estimate_loss()\n",
        "            print(f\"Step: {iter}, Loss: {losses}\")\n",
        "        X, y = get_batch(\"train\")\n",
        "        logits, loss = model(X, y)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "    print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhwI9uiGp5PT"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"./bigram_language_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"./bigram_language_model.pt\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67j_i4l_UlPP",
        "outputId": "08a67fa9-7719-4d60-beb3-5f79656606d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BigramLanguageModel(\n",
              "  (token_embedding_table): Embedding(65, 65)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzfsFVFLUr5m",
        "outputId": "4fd029b9-3c77-4818-fa24-e103ef1e4091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MPrrtano iru forealoiroret HEnk;\n",
            "CKES:MO tck in, d cer t ftanofallon bay ho s, andemen, meseveminds s; te worimyoin ie-s ofit thiWhou wowhedichea blare aned hy senInirmy a theint d polofind yon be ke imyol menatoulinor woeing brwimapise. hawe e wo IICis;\n",
            "ST:\n",
            "GRDo y'silH:\n",
            "FFortaperulllalop!\n",
            "Antheolirconourjura d f t wothrmu th?\n",
            "Whaling mas, h n t il c; d junlotir Whth'dlll my ay meras be:\n",
            "HERGSe ndonbust RIUCE:\n",
            "\n",
            "\n",
            "Anveaban; IOn hequ thitan nu tonm TESCorte y, d.\n",
            "Sl!\n",
            "HAUSHAny IE:\n",
            "ARERDO:\n",
            "BRolathon\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "batch_size = 64\n",
        "block_size = 256\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "eval_iters = 200\n",
        "n_embds = 384\n",
        "n_heads = 6\n",
        "head_size = n_embds // n_heads\n",
        "n_layers = 6\n",
        "dropout = 0.2\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [stoi[i] for i in s]\n",
        "decode = lambda l: \"\".join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    X = torch.stack([data[i:i + block_size] for i in ix])\n",
        "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    return X, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, y = get_batch(split)\n",
        "            logits, loss = model(X, y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embds, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embds, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embds, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        B, T, C = X.shape\n",
        "        k = self.key(X)\n",
        "        q = self.query(X)\n",
        "        wei = q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(X)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head() for _ in range(n_heads)])\n",
        "        self.proj = nn.Linear(head_size * n_heads, n_embds)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        out = torch.cat([h(X) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embds, n_embds * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_embds * 4, n_embds),\n",
        "            nn.Dropout(dropout), \n",
        "        )\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return self.net(X)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sa = MultiHeadAttention()\n",
        "        self.ffwd = FeedForward()\n",
        "        self.ln1 = nn.LayerNorm(n_embds)\n",
        "        self.ln2 = nn.LayerNorm(n_embds)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        X = X + self.sa(self.ln1(X))\n",
        "        X = X + self.ffwd(self.ln2(X))\n",
        "        return X\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embds)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embds)\n",
        "        self.blocks = nn.Sequential(*[Block() for _ in range(n_layers)])\n",
        "        self.ln_f = nn.LayerNorm(n_embds)\n",
        "        self.lm_head = nn.Linear(n_embds, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "    \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "    \n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        X = tok_emb + pos_emb\n",
        "        X = self.blocks(X)\n",
        "        X = self.ln_f(X)\n",
        "        logits = self.lm_head(X)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    model = GPTLanguageModel()\n",
        "    m = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    for iter in range(max_iters):\n",
        "        if iter % eval_interval == 0:\n",
        "            losses = estimate_loss()\n",
        "            print(f\"Step: {iter}, Loss: {losses}\")\n",
        "        X, y = get_batch(\"train\")\n",
        "        logits, loss = model(X, y)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "    print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ9DyYw4Uv3u",
        "outputId": "6b873d43-8a82-4fcc-e10b-11c3d40ddc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0, Loss: {'train': tensor(4.2221), 'val': tensor(4.2306)}\n",
            "Step: 500, Loss: {'train': tensor(1.7599), 'val': tensor(1.9162)}\n",
            "Step: 1000, Loss: {'train': tensor(1.3933), 'val': tensor(1.6023)}\n",
            "Step: 1500, Loss: {'train': tensor(1.2685), 'val': tensor(1.5291)}\n",
            "Step: 2000, Loss: {'train': tensor(1.1868), 'val': tensor(1.4955)}\n",
            "Step: 2500, Loss: {'train': tensor(1.1219), 'val': tensor(1.4860)}\n",
            "Step: 3000, Loss: {'train': tensor(1.0737), 'val': tensor(1.4861)}\n",
            "Step: 3500, Loss: {'train': tensor(1.0215), 'val': tensor(1.5081)}\n",
            "Step: 4000, Loss: {'train': tensor(0.9648), 'val': tensor(1.5082)}\n",
            "Step: 4500, Loss: {'train': tensor(0.9082), 'val': tensor(1.5378)}\n",
            "\n",
            "But with prison chariteds entremitted him\n",
            "if well, Camillia in's popularison.\n",
            "\n",
            "MISTRESS OVERDONE:\n",
            "Your first shall want too heavy that was the fearful venture.\n",
            "\n",
            "MISTRESSOP OF S:\n",
            "Master may shake her recovery heaven his right;\n",
            "Much trod many indeed soon stand here hours as are steep:\n",
            "More citizens afterward than this does and discords,\n",
            "From forward or them so buse,\n",
            "Or forth than nothing.\n",
            "\n",
            "SICINIUS:\n",
            "Give me the more than A!\n",
            "But what's this new knee, I'll say the of death,\n",
            "And I throw you much fria\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"./gpt_language_model.pt\")"
      ],
      "metadata": {
        "id": "nR8bOt36U_tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"./gpt_language_model.pt\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDJsLxFZVGRQ",
        "outputId": "2c41521c-3759-4754-e18b-d4a8425af515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTLanguageModel(\n",
              "  (token_embedding_table): Embedding(65, 384)\n",
              "  (position_embedding_table): Embedding(256, 384)\n",
              "  (blocks): Sequential(\n",
              "    (0): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): Block(\n",
              "      (sa): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-5): 6 x Head(\n",
              "            (key): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=384, out_features=64, bias=False)\n",
              "            (dropout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ffwd): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): Linear(in_features=384, out_features=65, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajaTb6scVLSm",
        "outputId": "91a83b45-d733-4e10-b0f3-1daa1c358abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "My lords, there's reason's face to answer me,\n",
            "For something what the disobed sun\n",
            "Doth death once and our children, with triumphants\n",
            "Will perceive a courtier envious to visit\n",
            "Tirench of the hand wrongs: seldom and your wrath,\n",
            "With this blood of slaves dreadful majesty,\n",
            "That it contempt shall from this hard-happiness\n",
            "Action water of a firmer's face,\n",
            "Trempted business on unthroat the field's death.\n",
            "Here in this; our aery of us sweet souls\n",
            "Are the waste in the field-shining toward with child.\n",
            "Ah, pe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yn3muF7i3diT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}